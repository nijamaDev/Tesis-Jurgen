\begin{spacing}{1.5}
  \begin{tightcenter}
    \section{4. Implementación y pruebas}
    \mylinespacing
  \end{tightcenter}

  \subsection{4.1 Implementando tecnologías}

  \textbf{Procedimiento}

  \textbf{Nota}: En el Anexo 1: Instalación y configuración de los computadores de la sala de cómputo Jürgen Tischer y Clúster Bochica del Departamento de Matemáticas de la Universidad del Valle, se detalla por completo la instalación y configuración que se llevó a cabo. Además, se detallan las herramientas disponibles y su utilidad.

  \subsubsection{4.1.1 Instalación en Sala de Cómputo Jürgen Tischer}

  \textbf{Procedimiento}

  \begin{itemize}
      \item Instalación de pcs
      \item Configuración de NFS en el principal
      \item Configuración de pcs (instalación de paquetes y demás)
      \item Instalación de Mathematica y gridMathematica
      \item Instalación nodos del clúster
      \item Configuración de servidores y switch
      \item Instalación conda
      \item Instalación de Jupyterhub con componentes adicionales
      \item Instalación y configuración de Slurm

  \end{itemize}

  \subsection{4.2 Pruebas de control}

  En el proceso de verificar el correcto funcionamiento de los computadores y las integraciones, se emplean diversas herramientas, como las presentadas a continuación.

  \subsubsection {4.2.1 Comprobar conectividad básica con pdsh}

  El comando \code{alias} se configuró para verificar el estado de los equipos
  en
  el clúster. Este comando permite lanzar un comando de manera más sencilla,
  por
  ejemplo, \code{pdsh xeon "hostname"}, que devuelve el nombre de
  todos los
  equipos encendidos y conectados correctamente por ssh. Además, si se utiliza
  el
  argumento \code{uptime} en vez de \code{hostname}, se puede obtener más
  información sobre el estado de cada nodo.

  El resultado se ve de esta forma :

  \definecolor{codebackground}{RGB}{240,240,240}
  % Color de fondo del código
  \definecolor{codecomment}{RGB}{100,100,100}
  % Color de los comentarios
  \definecolor{codekeyword}{RGB}{0,0,255}
  % Color de las palabras clave
  \definecolor{codestring}{RGB}{163,21,21}
  % Color de las cadenas de texto

  \lstset{
    backgroundcolor=\color{codebackground},
    commentstyle=\color{codecomment},
    keywordstyle=\color{codekeyword},
    stringstyle=\color{codestring},
    basicstyle=\footnotesize\ttfamily,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    frame=single,
    numberstyle=\tiny\color{codecomment},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    rulecolor=\color{codebackground}
  }
  \begin{lstlisting}[language=C]
      $ xeon "hostname"
      C4: C4
      E3: E3
      A2: A2
      ...
      B5: B5
  \end{lstlisting}

  \subsubsection {4.2.2 Comprobar funcionamiento en Mathematica}

  En Mathematica es fácil comprobar que la configuración paralela funciona
  correctamente. Para hacerlo, seleccione una configuración sencilla que
  incluya
  todos los nodos que desea utilizar. En nuestro caso, configuramos Lightweight
  Grid en las opciones de configuración paralela del kernel, con un kernel
  disponible para cada nodo. También es necesario desactivar
  \textit{RemoteKernel
    Objects}, que es un configurador automático que, por defecto, solo usa los
  kernels locales e ignora toda la configuración que se le coloca. Los kernels
  configurados se muestran en la Figura \ref{fig:etiqueta1}.  \newline  \newline

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{mat.png}
    \caption{Configuración paralela en Mathematica}
    \label{fig:etiqueta1}
  \end{figure}

  Una vez que se haya completado esta configuración, podrás abrir un nuevo
  cuaderno (notebook) y escribir la siguiente instrucción: \code{LaunchKernels[
      ]}. De esta manera, la aplicación tratará de conectarse con los kernels
  configurados en cada nodo, tal como se muestra en la Figura
  \ref{fig:etiqueta2}

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{mat1.png}
    \caption{Conexión de kernels y nodos}
    \label{fig:etiqueta2}
  \end{figure}

  En caso de que todo salga bien, se muestra una lista con todos los kernels
  iniciados, como se indica en la Figura \ref{fig:etiqueta3}

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{mat4.png}
    \caption{Kenerls iniciados}
    \label{fig:etiqueta3}
  \end{figure}

  Si hay un error, Mathematica lo señalará. Normalmente el error incluirá
  información sobre el nodo que presenta problemas, así como una breve
  descripción del problema y posibles soluciones a aplicar, en la Figura
  \ref{fig:etiqueta4} se puede observa un error en Mathematica.

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{mat3.png}
    \caption{Información de error}
    \label{fig:etiqueta4}
  \end{figure}

  \subsubsection {4.2.3 Comprobar funcionamiento en Slurm}

  En Slurm, hay varios comandos básicos que nos permiten ver información sobre
  el
  estado de los nodos configurados.

  \begin{itemize}
    \item \textbf{sinfo}: Muestra el estado de los nodos. Es la primera
          herramienta que se debe utilizar para visualizar si hay algún
          problema de
          comunicación con los nodos.
    \item \textbf{srun}: Agrega una tarea a la cola de manera activa.
    \item \textbf{squeue}: Muestra la lista de tareas en cola, tanto pendientes
          como en ejecución.
    \item \textbf{scancel}: Cancela una tarea que se encuentra en la cola.
    \item \textbf{scontrol}: Se utiliza principalmente para cambiar el estado
          de los nodos.
  \end{itemize}

  Es posible probar rápidamente el funcionamiento de los nodos con \code{srun},
  de manera similar a como se utilizaba \code{pdsh}. En este caso, el comando
  utilizado es \code{srun -N10 hostname}. Esto solicitará a 10 nodos
  disponibles
  que ejecuten el comando \code{hostname}, devolviendo sus nombres. Si se
  utiliza
  el número total de nodos y todos devuelven su nombre, entonces la
  comunicación
  básica funciona. Sin embargo, solo esta prueba no es suficiente para
  determinar
  un problema de sincronización, ya que puede haber un problema en la
  comunicación del número de nodos en la tarea, donde cada nodo cree que es el
  único que ejecuta la tarea y no se da cuenta de que hay otros.

  \textbf{Helloworld Paralelo con C y C++}

  Para verificar la comunicación completa, se utilizó el programa de ``hola
  mundo''
  en paralelo con MPI, escrito en C. Esto se basa en el tutorial de
  mpitutorial.com \cite{HelloC}:

  \definecolor{codebackground}{RGB}{240,240,240}
  % Color de fondo del código
  \definecolor{codecomment}{RGB}{100,100,100}
  % Color de los comentarios
  \definecolor{codekeyword}{RGB}{0,0,255}
  % Color de las palabras clave
  \definecolor{codestring}{RGB}{163,21,21}
  % Color de las cadenas de texto

  \lstset{
    backgroundcolor=\color{codebackground},
    commentstyle=\color{codecomment},
    keywordstyle=\color{codekeyword},
    stringstyle=\color{codestring},
    basicstyle=\footnotesize\ttfamily,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    frame=single,
    numberstyle=\tiny\color{codecomment},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    rulecolor=\color{codebackground}
  }

  \begin{lstlisting}[language=C]
    #include <stdio.h>
    #include <unistd.h>
    #include <mpi.h>
    
    int main(int argc, char** argv)
    {
      // Init the MPI environment
      MPI_Init(NULL, NULL);
      // Get the number of processes
      int world_size;
      MPI_Comm_size(MPI_COMM_WORLD, &world_size);
      // Get the rank of the process
      int world_rank;
      MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
      // Get the name of the processor
      char processor_name[MPI_MAX_PROCESSOR_NAME];
      int name_len;
      MPI_Get_processor_name(processor_name, &name_len);
      // Print a hello world message
      printf("Hello, World! from node %s, rank %d out of %d processors\n",
             processor_name, world_rank + 1, world_size);
      // Finalize the MPI environment
      MPI_Finalize();
    }
    \end{lstlisting}

  Para compilar este código es necesario contar con mpicc. Para hacerlo, se
  debe utilizar el siguiente comando: \code{mpicc c-mpi-hello.c -o
    c-mpi-hello}.

  Luego, el archivo debe ser accesible desde todas las máquinas en la misma
  ubicación. Para lograr esto, se utilizó un NFS, tal como se indica en la guía
  adjunta en el apartado NFS.

  Para ejecutar el código, se debe utilizar el comando \code{srun -N10
    /nfs/c-mpi-hello}.Esto asignará 10 nodos, cada uno con un hilo de proceso. El resultado tiene el siguiente formato :

    \begin{lstlisting}[language=C]
      $ srun -N4 c-mpi-hello
      Hello, World! from node bochica2, rank 2 out of 4 processors
      Hello, World! from node bochica3, rank 3 out of 4 processors
      Hello, World! from node bochica1, rank 1 out of 4     processors
      Hello, World! from node bochica4, rank 4 out of 4 processors
    \end{lstlisting}

  \textbf{Helloworld Paralelo con Python}

  Se puede lograr lo mismo utilizando Python. Se recomienda preparar un
  entorno utilizando conda o mamba en el NFS para que esté disponible para
  todos
  los nodos involucrados. Además, el entorno debe contener el paquete
  \code{mpi4py}. En nuestro caso, utilizamos la implementación de \code{mpich}.
  El entorno fue creado con el comando \code{conda create -p /nfs/anaconda}
    \code{anaconda mpi4py mpich}.

    En el siguiente código se muestra un programa en Python utilizando mpi4py para imprimir Hello World

    \begin{lstlisting}[language=python]
      # py-mpi-hello.py
      """
      Parallel Hello World
      """

      from mpi4py import MPI
      import sys
      import getpass

      size = MPI.COMM_WORLD.Get_size()
      rank = MPI.COMM_WORLD.Get_rank()
      name = MPI.Get_processor_name()
      user = getpass.getuser()

      sys.stdout.write(
      "%s: Hello, World! I am process %d of %d on %s.\n"
      % (user, rank+1, size, name))

    \end{lstlisting}
      
    Para activar el entorno de conda durante la ejecución de cada nodo, es más conveniente utilizar un archivo de sbatch que directamente con srun como se muestra a continuación:

    \begin{lstlisting}[language=python]
      # py-mpi-hello.sbatch
      #!/bin/sh
      #SBATCH -o /nfs/sbatch-examples/helloworld/py-mpi-hello.out
      #SBATCH --nodes=4
      #SBATCH --ntasks-per-node=1

      # Load conda commands from local installation
      source /opt/conda/etc/profile.d/conda.sh

      # Activate shared conda on nfs
      conda activate /nfs/conda

      # Run mpi example
      srun python /nfs/sbatch-examples/helloworld/py-mpi-hello.py
    \end{lstlisting}

    Utilizamos \code{sbatch py-mpi-hello.sbatch} para ejecutar la prueba y verificar su funcionamiento. El resultado debe ser como se muestra a continuación:

      \begin{lstlisting}[language=python]
      estudiante: Hello, World! I am process 2 of 4 on bochica2.
      estudiante: Hello, World! I am process 3 of 4 on bochica3.
      estudiante: Hello, World! I am process 4 of 4 on bochica4.
      estudiante: Hello, World! I am process 1 of 4 on bochica1. 
      \end{lstlisting}
      
  \subsection{4.3 Pruebas de eficiencia}  \label{chap:4.3}

  Se prepararon y realizaron dos pruebas para medir la eficiencia de los sistemas implementados.

      \textbf{Prueba de gridMathematica}

      Para probar el rendimiento en singular, multi-proceso y multi-máquina utilizamos el código de uno de los proyectos que se beneficiaron con la implementación de esta tesis (ver Capítulo 5, Influencia en proyectos destacados, para más detalles).

      De este código nos interesaremos por una parte en particular en donde existe una variable de puntos que afectan a un problema lineal, el cual resulta óptimo para probar el rendimiento de los sistemas.

      Preprint del proyecto mencionado y código de GitHub a utilizar. \cite{preprint} \cite{git}

      En los resultados mostrados solo se considera el tiempo de ejecución del cálculo realizado, no se toma en cuenta el tiempo que tarda en conectar los nodos ni en preparar las variables.

      Para las pruebas utilizamos diferentes escenarios, un DELL PRECISION T3610 equipado con Intel Xeon E5-1620 v2 @ 3.9GHz (4 núcleos físicos, 8 hilos de ejecución), lo comparamos con un HP Z1 equipado con un Intel i9-10900 @ 5.2 GHz para ver la diferencia de velocidad al escalar verticalmente una máquina y luego con el mismo Intel Xeon pero con 10 de esos.

      \textbf{Resultados Mathematica}

      Procesadores utilizados : 

      Xeon = Xeon E5-1620 v2 @ 3.9GHz 

      i9 = Intel i9-10900 @ 5.2 GHz

      \begin{figure}[h]
            \centering
            \includegraphics[width=0.5\textwidth]{tab1.png}
            \caption{Resultados Mathematica}
            \label{fig:etiqueta}
          \end{figure}

      En la figura 10 del anexo 2 podemos observar

      n=500

      \begin{figure}[h]
            \centering
            \includegraphics[width=0.5\textwidth]{tab2.png}
            \caption{Resultados Mathematica}
            \label{fig:etiqueta}
      \end{figure}

      En la siguiente gráfica se muestra la mejora porcentual en la eficiencia de generación de puntos por segundo.

      \begin{figure}[h]
            \centering
            \includegraphics[width=0.5\textwidth]{tab3.png}
            \caption{Resultados Mathematica}
            \label{fig:etiqueta}
      \end{figure}

\textbf{Slurm - The Linpack Benchmark para sistemas distribuidos}

El benchmark Linpack es una prueba de rendimiento computacional que mide la capacidad de cálculo y eficiencia de un sistema informático en términos de velocidad y procesamiento numérico. Fue diseñado por Jack Dongarra en los años 70 en el Laboratorio Nacional de Oak Ridge, y se ha convertido en un estándar en el campo de la supercomputación y el rendimiento de los sistemas informáticos. Esta prueba utiliza la resolución de un sistema complejo de ecuaciones lineales como criterio. \cite{linpack}, \cite{hpl-linpack}, \cite{faq-linpack}

Con esta prueba, es posible evaluar el rendimiento y la capacidad de procesamiento de diferentes configuraciones computacionales y compararlos. En este proyecto, se utilizó Slurm para ejecutar la prueba en sistemas distribuidos. Se realizaron pruebas en diferentes configuraciones de nodos y núcleos por nodo, lo que permitió medir la eficiencia y el rendimiento en distintos escenarios. Los resultados se registraron para una evaluación detallada.

Para configurar adecuadamente la prueba, se utilizó una herramienta web que sugiere una configuración según la cantidad de nodos, la cantidad de tareas por nodo y la cantidad de memoria. \cite{tune-hpl-dat-file}

Durante la realización de esta investigación, se presentaron circunstancias imprevistas que afectaron el desarrollo de las pruebas de rendimiento en el entorno del clúster Bochica. Se detectaron problemas de mantenimiento en dicho entorno que comprometían su disponibilidad y estabilidad, poniendo en riesgo la precisión y confiabilidad de los resultados obtenidos.

En vista de esta situación, se tomó la decisión de replicar el entorno de slurm utilizando los 30 computadores Xeon E5-1620 v2 de la sala, mismos computadores de la prueba de Mathematica, en donde se procedió a ejecutar las pruebas de rendimiento. Aunque esta medida no estaba contemplada originalmente en el plan de investigación, se consideró como la mejor alternativa disponible para asegurar la integridad de las pruebas y la obtención de resultados fiables.

Cabe destacar que se tomaron todas las medidas necesarias para garantizar que el entorno secundario contara con una configuración similar al entorno Bochica, asimismo se minimizaron las diferencias de entorno a fin de mantener la consistencia en las pruebas realizadas.

\textbf{Resultados Slurm}

\begin{figure}[h]
      \centering
      \includegraphics[width=0.5\textwidth]{a.png}
      \caption{Resultados Slurm}
      \label{fig:etiqueta}
\end{figure}

En el contexto del benchmark LINPACK, los datos obtenidos describen los resultados de ejecutar el benchmark en diferentes configuraciones de nodos y tareas por nodo.

\begin{itemize}
      \item "Nodos": representa el número de nodos utilizados en la ejecución del benchmark.
      \item "Tareas por nodo": indica el número de tareas (hilos de ejecución) asignadas a cada nodo.
      \item "Tiempo": es el tiempo en segundos que tardó el sistema en ejecutar el benchmark LINPACK en la configuración dada.
      \item "Gflops": representa el rendimiento medido en giga operaciones de punto flotante por segundo (GFLOPS) alcanzado durante la ejecución del benchmark.
\end{itemize}

En general, estos datos proporcionan una idea de cómo el rendimiento del sistema varía con respecto al número de nodos y tareas por nodo. A medida que se agregan más nodos y tareas, en general, el rendimiento mejora, aunque no de manera lineal debido a la comunicación y la sobrecarga asociadas con la coordinación entre nodos.

  \subsection{4.4 Automatización - Facilitar el uso}   \label{chap:4.4}

  \subsubsection{4.4.1 Scripts}

  En el desarrollo de este proyecto, se llevaron a cabo diversos scripts de
  automatización que permiten realizar tareas de mantenimiento y configuración
  de
  manera más eficiente y sistemática. Estos scripts han sido diseñados para
  optimizar procesos específicos dentro del proyecto y su implementación ha
  permitido reducir el tiempo de ejecución de tareas repetitivas y mejorar la
  calidad del trabajo.

  Estas son las funciones principales de los scripts de automatización:

  \begin{itemize}
    \item Encendido y apagado de computadores.
    \item Verificación del estado de los computadores y servicios.
    \item Actualización de software.
    \item Instalación de paquetes de software.
    \item Configuración completa de un nuevo equipo recién instalado o de
          un equipo antiguo formateado.
  \end{itemize}

  Esto permitirá minimizar las tareas comunes y de mantenimiento requeridas
  con menor esfuerzo. Además, estos scripts son altamente escalables y pueden
  ser
  adaptados para su uso en proyectos futuros, lo que representa una inversión a
  largo plazo en la mejora de la eficiencia y la calidad del trabajo.\cite{github}

  \subsection{4.5 Problemas encontrados}
  En el desarrollo de este proyecto, se presentaron problemas tanto previstos
  como inesperados, los cuales serán mencionados a continuación.

  \subsubsection{4.5.1 Problemas esperados}

  \begin{enumerate}
    \item \textbf{Heterogeneidad de los recursos computacionales:} El clúster
          Bochica y la sala de computación Jürgen Tischer contienen una
          variedad de
          recursos computacionales, incluyendo diferentes tipos de
          computadoras, sistemas
          operativos y versiones de software. Esto puede dificultar la
          optimización del
          sistema distribuido diseñado y requerir una mayor planificación y
          flexibilidad
          en el diseño y la implementación.
    \item \textbf{Antigüedad de los computadores:} Algunos de los computadores
          en el clúster Bochica y la sala de computación Jürgen Tischer son
          antiguos y
          pueden tener un impacto en la eficiencia y la capacidad de ejecutar
          tareas de
          investigación de manera óptima.
    \item \textbf{Dificultades en la adaptación a las nuevas herramientas:} La
          implementación de nuevas herramientas y tecnologías puede requerir un
          período
          de adaptación y aprendizaje para los usuarios, lo que puede retrasar
          los
          procesos de investigación y enseñanza. Además, pueden surgir
          problemas técnicos
          durante la instalación y configuración de las herramientas, lo que
          puede
          interferir en la eficiencia y productividad.
  \end{enumerate}

  \subsubsection{4.5.2 Problemas no esperados}

  \textbf{Problemas con el software}

  \begin{itemize}
    \item Problemas de licencias: Parte del software utilizado era
          propietario y resultó problematico el correcto uso de estas
          licencias,
          especialmente el software de Wolfram Mathematica.
  \end{itemize}

  \textbf{Problemas con el hardward}

  \begin{itemize}
    \item Cables mal acomodados: Los cables del clúster estaban mal
          acomodados, lo que generaba una dificultad para conocer las
          diferentes
          interconexiones entre los recursos.
    \item Cables faltantes: Se encontró que se requería un cable serial
          para la adecuada configuración de un switch que permite la
          interconexión entre
          los equipos del clúster.
    \item Permisos olvidados: Varios equipos del clúster debido a su
          desuso, se habían perdido las credenciales para utilizarlos de la
          manera
          adecuada
    \item Partes que requerían mantenimiento: Algunas partes del hardware
          requerían mantenimiento para su óptimo funcionamiento, pero esto no
          se había
          realizado.
    \item Desconocimiento de las limitaciones del hardware: Al principio no
          se conocían las limitaciones del hardware, lo que dificultaba su
          correcto uso y
          aprovechamiento.
    \item Hardware mal acomodado: El hardware estaba mal acomodado, lo que
          generaba problemas en la conexión y en el acceso a los recursos
          computacionales.
  \end{itemize}

  \textbf{Problemas con la Implementación del Sistema Distribuido}

  \begin{itemize}
    \item Falta de documentación clara para la implementación: La
          documentación para la implementación del sistema distribuido no era
          clara, lo
          que dificultaba su correcta implementación.
    \item Dificultades en la integración de los diferentes componentes del
          sistema: Se encontraron dificultades en la integración de los
          diferentes
          componentes del sistema distribuido, lo que limitaba su correcto
          funcionamiento.
    \item Limitaciones en la capacidad de paralelización: Se encontraron
          limitaciones en la capacidad de paralelización del sistema
          distribuido, lo que
          disminuía su eficiencia y efectividad.
  \end{itemize}

  \textbf{Problemas con las Herramientas Instaladas}

  \begin{itemize}
    \item Falta de compatibilidad con otras aplicaciones: Las herramientas
          instaladas no eran compatibles con otras aplicaciones, lo que
          limitaba su uso y
          efectividad.
    \item Dificultades en la configuración y uso: Se encontraron
          dificultades en la configuración y uso de las herramientas
          instaladas, lo que
          disminuía su efectividad.
    \item Falta de documentación y apoyo técnico: La falta de documentación
          y apoyo técnico para las herramientas instaladas limitaba su uso y
          efectividad.
  \end{itemize}

  \textbf{Problemas con las Pruebas de Rendimiento}

  \begin{itemize}
    \item Falta de recursos y tiempo para realizar las pruebas: No se
          contaba con los recursos y tiempo necesario para realizar las pruebas
          de
          rendimiento, lo que limitaba la evaluación de la infraestructura y
          las
          aplicaciones implementadas.
    \item Falta de una metodología clara para la realización de las
          pruebas: No había una metodología clara para la realización de las
          pruebas de
          rendimiento, lo que generaba incertidumbre en los resultados y
          dificultades en
          la interpretación de los mismos.
    \item Dificultades en la comparación de resultados con otras
          infraestructuras: Se encontraron dificultades en la comparación de
          los
          resultados obtenidos con otras infraestructuras similares, lo que
          disminuía la
          validez de los resultados.
    \item Falta de un sistema de seguimiento y monitoreo de las pruebas: No
          había un sistema de seguimiento y monitoreo de las pruebas, lo que
          dificultaba
          la identificación y solución de posibles problemas y limitaba la
          mejora
          continua de la infraestructura.
  \end{itemize}

  \mylinespacing
  \mylinespacing
  \begin{tightcenter}
  \end{tightcenter}
\end{spacing}